{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/johnmwadime/chatbot?scriptVersionId=97905879\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"#### <p>We will be installing python libraries; \n<ul><li>nltk</li> <li>NumPy</li><li>gTTs (google text-to-speech)</li><li>mpg123 and portaudio, for accessing the microphone from the system</li><li>SpeechRecognition</li><li>scikit-learn</li></ul></p>","metadata":{}},{"cell_type":"code","source":" #!pip install --upgrade pip\n#!pip install --upgrade setuptools\n#pip install SpeechRecognition numpy gTTs sklearn\n#!pip install pyAudioAnalysis\n#!pip install PyAudio\n#!pip install portaudio\n#pip install mpg123","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <p>Importing neccessary libraries and modules</p> ","metadata":{}},{"cell_type":"code","source":"#importing necessary libraries\nimport io\nimport random\nimport string\nimport warnings\nimport mpg123\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport warnings\nfrom gtts import gTTS #text to speech conversion\nimport os \nwarnings.filterwarnings('ignore')\nimport speech_recognition as sr \nimport nltk\nfrom nltk.stem import WordNetLemmatizer\n#for downloading package files can be commented after First run\n#nltk.download('popular', quiet=True)\n#nltk.download('nps_chat',quiet=True)\n#nltk.download('punkt') \n#nltk.download('wordnet')\n#intro_join =\"../input/intro-join/intro_join.txt\"","metadata":{"execution":{"iopub.status.busy":"2022-03-14T09:17:26.146347Z","iopub.execute_input":"2022-03-14T09:17:26.146851Z","iopub.status.idle":"2022-03-14T09:17:26.238771Z","shell.execute_reply.started":"2022-03-14T09:17:26.146761Z","shell.execute_reply":"2022-03-14T09:17:26.237588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <p>We will write a function to classify user input, which uses nps_chat corpora and naive Bayes classifier to categorize the input type by classifying them into listed categories.Where else Bot will answer only to Question type classes.</p>","metadata":{}},{"cell_type":"code","source":"posts = nltk.corpus.nps_chat.xml_posts()[:10000]\n# To Recognise input type as QUES. \ndef dialogue_act_features(post):\n    features = {}\n    for word in nltk.word_tokenize(post):\n        features['contains({})'.format(word.lower())] = True\n    return features\nfeaturesets = [(dialogue_act_features(post.text), post.get('class')) for post in posts]\nsize = int(len(featuresets) * 0.1)\ntrain_set, test_set = featuresets[size:], featuresets[:size]\nclassifier = nltk.NaiveBayesClassifier.train(train_set)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T21:55:58.987274Z","iopub.execute_input":"2022-03-12T21:55:58.987634Z","iopub.status.idle":"2022-03-12T21:56:04.589907Z","shell.execute_reply.started":"2022-03-12T21:55:58.98759Z","shell.execute_reply":"2022-03-12T21:56:04.588891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <p>To make our chatbot more engaging and interactive, we will create a greeting function.</p>","metadata":{}},{"cell_type":"code","source":"# Keyword Matching\nGREETING_INPUTS = (\"hello\",\"heey\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\nGREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\ndef greeting(sentence):\n    \"\"\"If user's input is a greeting, return a greeting response\"\"\"\n    for word in sentence.split():\n        if word.lower() in GREETING_INPUTS:\n            return random.choice(GREETING_RESPONSES)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T21:56:04.591264Z","iopub.execute_input":"2022-03-12T21:56:04.591598Z","iopub.status.idle":"2022-03-12T21:56:04.597981Z","shell.execute_reply.started":"2022-03-12T21:56:04.591557Z","shell.execute_reply":"2022-03-12T21:56:04.596867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <p>We will call Corpus of our chatbot and perform some NLP pre-processing steps on it, i.e., Sentence and Word Tokenization, Lemmatization, Normalisation. We are calling our Corpus as intro_join. </p>","metadata":{}},{"cell_type":"code","source":"#Reading in the input_corpus\nwith open('../input/intro-join/intro_join.txt','r', encoding='utf8', errors ='ignore') as fin:\n    raw = fin.read().lower()\n#TOkenisation\nsent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \nword_tokens = nltk.word_tokenize(raw)# converts to list of words\n# Preprocessing\nlemmer = WordNetLemmatizer()\ndef LemTokens(tokens):\n    return [lemmer.lemmatize(token) for token in tokens]\nremove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\ndef LemNormalize(text):\n    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T21:56:04.59974Z","iopub.execute_input":"2022-03-12T21:56:04.599992Z","iopub.status.idle":"2022-03-12T21:56:04.63904Z","shell.execute_reply.started":"2022-03-12T21:56:04.599962Z","shell.execute_reply":"2022-03-12T21:56:04.637981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <p>To make it look appealing, we will add the color pallet, which is a list of functions using the format command, for adding color to std terminal output.</p>","metadata":{}},{"cell_type":"code","source":"#colour palet\ndef prRed(skk): print(\"\\033[91m {}\\033[00m\" .format(skk)) \ndef prGreen(skk): print(\"\\033[92m {}\\033[00m\" .format(skk)) \ndef prYellow(skk): print(\"\\033[93m {}\\033[00m\" .format(skk)) \ndef prLightPurple(skk): print(\"\\033[94m {}\\033[00m\" .format(skk)) \ndef prPurple(skk): print(\"\\033[95m {}\\033[00m\" .format(skk)) \ndef prCyan(skk): print(\"\\033[96m {}\\033[00m\" .format(skk)) \ndef prLightGray(skk): print(\"\\033[97m {}\\033[00m\" .format(skk)) \ndef prBlack(skk): print(\"\\033[98m {}\\033[00m\" .format(skk))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T21:56:04.640407Z","iopub.execute_input":"2022-03-12T21:56:04.640723Z","iopub.status.idle":"2022-03-12T21:56:04.648735Z","shell.execute_reply.started":"2022-03-12T21:56:04.640682Z","shell.execute_reply":"2022-03-12T21:56:04.647845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <p>Now we will create a function for processing the user response converting it into a vectorized form and get the best result from Corpus via computing TF-IDF cosine similarity between the question and answer.</p>","metadata":{}},{"cell_type":"code","source":"# Generating response and processing \ndef response(user_response):\n    robo_response=''\n    sent_tokens.append(user_response)\n    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n    tfidf = TfidfVec.fit_transform(sent_tokens)\n    vals = cosine_similarity(tfidf[-1], tfidf)\n    idx=vals.argsort()[0][-2]\n    flat = vals.flatten()\n    flat.sort()\n    req_tfidf = flat[-2]\n    if(req_tfidf==0):\n        robo_response=robo_response+\"I am sorry! I don't understand you\"\n        return robo_response\n    else:\n        robo_response = robo_response+sent_tokens[idx]\n        return robo_response","metadata":{"execution":{"iopub.status.busy":"2022-03-12T21:56:04.649984Z","iopub.execute_input":"2022-03-12T21:56:04.650332Z","iopub.status.idle":"2022-03-12T21:56:04.665713Z","shell.execute_reply.started":"2022-03-12T21:56:04.650275Z","shell.execute_reply":"2022-03-12T21:56:04.664728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <p>Now we are almost ready to print the First message from Bot ðŸ˜ƒ</p>","metadata":{}},{"cell_type":"code","source":"#Recording voice input using microphone \nfile = \"./file.mp3\"\nflag=True\nfst=\"My name is John. I will answer your inquiries about Python. Welcome! \"\ntts = gTTS(fst, lang= language, slow= False)\ntts.save(file)\nos.system(file )\nr = sr.Recognizer()\nprYellow(fst)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T22:21:34.484077Z","iopub.execute_input":"2022-03-12T22:21:34.486014Z","iopub.status.idle":"2022-03-12T22:21:34.841799Z","shell.execute_reply.started":"2022-03-12T22:21:34.485923Z","shell.execute_reply":"2022-03-12T22:21:34.840811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <p>It is using speech recognition for registering user input using the microphone. Converting it into text form, Searching for its answers from the processed Corpus, and returning the output using text-to-speech. It will continue taking user input and answering until the user says Bye/Goodbye.</p>","metadata":{}},{"cell_type":"code","source":"\nwhile(flag==True):\n    with sr.Microphone() as source:\n        audio= r.listen(source)\n    try:\n        user_response = format(r.recognize(audio))\n        print(\"\\033[91m {}\\033[00m\" .format(\"YOU SAID : \"+user_response))\n    except sr.UnknownValueError:\n        prYellow(\"Oops! Didn't catch that\")\n        pass\n    \n    #user_response = input()\n    #user_response=user_response.lower()\n    clas=classifier.classify(dialogue_act_features(user_response))\n    if(clas!='Bye'):\n        if(clas=='Emotion'):\n            flag=False\n            prYellow(\"John: You are welcome..\")\n        else:\n            if(greeting(user_response)!=None):\n                print(\"\\033[93m {}\\033[00m\" .format(\"John: \"+greeting(user_response)))\n            else:\n                print(\"\\033[93m {}\\033[00m\" .format(\"John: \",end=\"\"))\n                res=(response(user_response))\n                prYellow(res)\n                sent_tokens.remove(user_response)\n                tts = gTTS(res, lang = language,slow = False)\n                tts.save(file)\n                os.system(file)\n    else:\n        flag=False","metadata":{"execution":{"iopub.status.busy":"2022-03-12T22:07:57.643998Z","iopub.execute_input":"2022-03-12T22:07:57.644812Z","iopub.status.idle":"2022-03-12T22:07:57.678076Z","shell.execute_reply.started":"2022-03-12T22:07:57.644766Z","shell.execute_reply":"2022-03-12T22:07:57.675793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### YET to explain every part of my code. Meanwhile, i need someone to brainstorm with me on how to install portaudio and pyaudio  for my notebook","metadata":{}}]}